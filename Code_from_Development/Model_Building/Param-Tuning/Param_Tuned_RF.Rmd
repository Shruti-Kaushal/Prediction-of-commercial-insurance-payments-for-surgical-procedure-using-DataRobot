---
title: "XGBoost Random Forest Model"
author: "Ryan Rogers"
date: "11/7/2022"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(xgboost)
library(caret)
library(MLmetrics)
source(file = "../../Common_Functions/processing_functions.R") # import of data_split transformation
source(file = "../../Common_Functions/baseline_model.R") # import of baseline model
```

## Modeling with threshold 35 number of claims

```{r, warning = FALSE, message = FALSE}
data <- read.csv("../../Data_Files/JnJ_Files/priv_mcare_f_pay_2022Oct18.csv")
hospital_data <- read.csv("../../Data_Files/JnJ_Files/Hospital_Master_Sheet.csv")
```

## One hot encoding, etc.

```{r}
data <- data %>% select(-CBSA_NAME)
ohe <- dummyVars("~ .", data = data)
data <- data.frame(predict(ohe, newdata=data))
```


```{r, warning = FALSE, message = FALSE}
# Hospital data aggregation - validated for sameness
hospitals_msa <- hospital_data %>% aggregate_hospital_features()
rm(hospital_data)

# Data split into model data and predict - varies from original slightly
split_dataset <- data %>% data_split(count_thresh = 34)
working_set <- split_dataset[[1]]
predict_set <- split_dataset[[2]]

model_data <- left_join(working_set, hospitals_msa, by = "msa")  %>%
  select(-priv_pay_mean, -priv_pay_iqr, -mcare_pay_mean, -mcare_pay_sd, -Urban, -msa)
rm(working_set)

predict_data <- left_join(predict_set, hospitals_msa, by = "msa")  %>%
  select(-priv_pay_mean, -priv_pay_iqr, -mcare_pay_mean, -mcare_pay_sd, -Urban, -msa)
rm(predict_set)

# Train test split
train_test_data <- model_data %>% train_test_split(proportion_train = 0.8)
rm(model_data)

train <- train_test_data[[1]]
test <- train_test_data[[2]]

train <- train %>% drop_na()
test <- test %>% drop_na()
```


## Modeling

For parameter info, see: https://www.r-bloggers.com/2021/05/strong-random-forests-with-xgboost/ , https://cran.r-project.org/web/packages/xgboost/xgboost.pdf , and https://xgboost.readthedocs.io/en/latest/tutorials/rf.html

```{r, warning = FALSE, message = FALSE}

train_X <- train %>% select(-priv_pay_median) %>% as.matrix()
train_y <- train %>% select(priv_pay_median) %>% as.matrix()

mono_cons <- rep(0, 117)
mono_cons[3] <- 1

model_params = list(
  base_score=0.5,
  booster='gbtree',
  colsample_bylevel=1,
  colsample_bytree=1,
  enable_categorical=FALSE,
  gamma=0,
  gpu_id=-1,
  interaction_constraints='',
  max_delta_step=0,
  min_child_weight=1,
  missing=NaN,
  n_estimators=250,
  n_jobs=8,
  predictor='auto',
  reg_alpha=0,
  scale_pos_weight=1,
  tree_method='exact',
  validate_parameters=1,
  monotone_constraints = mono_cons,
  learning_rate = 1,
  max_depth = 25,
  num_parallel_tree = 250,
  objective = 'reg:squarederror',
  subsample = 0.8,
  random_state = 123,
  reg_lambda = 0
)

# Fit Model on training data
XGB <- xgboost(
  data = train_X,
  label = train_y,
  params = model_params,
  nrounds = 1
)


train_predict <- train %>%
  mutate(pred_priv_pay_median = predict(XGB, train_X)) %>%
  filter(!is.na(pred_priv_pay_median))

trn_m = MAPE(train_predict$pred_priv_pay_median, train_predict$priv_pay_median)

train_mape_percent = mean(abs((train_predict$priv_pay_median - train_predict$pred_priv_pay_median)/train_predict$priv_pay_median),na.rm = T)*100
```

```{r, warning = FALSE, message = FALSE}
test_X <- test %>% select(-priv_pay_median) %>% as.matrix()

test_predict <- test %>%
  mutate(pred_priv_pay_median = predict(XGB, test_X)) %>%
  filter(!is.na(pred_priv_pay_median))
tst_m = MAPE(test_predict$pred_priv_pay_median, test_predict$priv_pay_median)
test_mape_percent = mean(abs((test_predict$priv_pay_median - test_predict$pred_priv_pay_median)/test_predict$priv_pay_median),na.rm = T)*100
```

```{r}
cat("With Threshold >=35 claims for training set:\n")
cat("Train MAPE:" , round(train_mape_percent, 2), "%\n")
cat("Test MAPE:" , round(test_mape_percent, 2), "%\n")
```

