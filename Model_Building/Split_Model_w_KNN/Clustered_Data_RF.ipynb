{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "81eb7c6e",
   "metadata": {},
   "source": [
    "# Tree-based Models, with Clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13a4fdd5",
   "metadata": {},
   "source": [
    "## Library Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c707dca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Necessary code to import our helper functions\n",
    "import sys\n",
    "sys.path.append(\"../..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "331fb943",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rogmo\\anaconda3\\lib\\site-packages\\xgboost\\compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n"
     ]
    }
   ],
   "source": [
    "# Library imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from matplotlib import pyplot as plt\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from Common_Functions import add_unique_identifier, data_cleaning, hospital_data_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a7996c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_split(data, count_col_name = 'priv_count', count_thresh = 50):\n",
    "    \"\"\"\n",
    "    This function splits the data into model set and future set. Model set is the data used to train, evaluate\n",
    "    test the model. Future data is what the model needs to predict on.\n",
    "    \n",
    "    Args:\n",
    "    data (pandas: DataFrame) - a pandas data frame with at least 3 columns - \"priv_pay_mean\", \"priv_pay_median\" and count_col_name\n",
    "    count_col_name (str) - name of the column which is thresholded to make the split\n",
    "    count_thresh (int) - threshold value used to split data on count_col_name\n",
    "    \n",
    "    Returns:\n",
    "    model_data (pandas: DataFrame) - data frame with observations that will be used to train and test model\n",
    "    future_data (pandas: DataFrame) - data frame with all observations on which model will make predictions\n",
    "    \"\"\"\n",
    "    data = data[(data['priv_pay_median'] > 0) | (data['priv_pay_median'].isnull())]\n",
    "    future_data = data[(data[count_col_name] <= count_thresh) | (data[count_col_name].isnull())]\n",
    "    model_data = data[data[count_col_name] > count_thresh]\n",
    "    model_data = model_data[model_data.priv_pay_median.notnull()]\n",
    "    return model_data, future_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ddd88ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method from Shruti's code\n",
    "def standardize_data(train_data, val_data):\n",
    "    train_temp = train_data.drop(columns = ['site','cluster','lat','lon'])\n",
    "    val_temp = val_data.drop(columns = ['site','cluster','lat','lon'])\n",
    "    \n",
    "    scaler = MinMaxScaler()\n",
    "    \n",
    "    train_data_scaled = scaler.fit_transform(train_temp)\n",
    "    train_data_scaled = pd.DataFrame(train_data_scaled, columns = train_temp.columns)\n",
    "    train_data_scaled['cluster'] = train_data['cluster'].to_list()\n",
    "    train_data_scaled['site'] = train_data['site'].to_list()\n",
    "    train_data_scaled['lat'] = train_data['lat'].to_list()\n",
    "    train_data_scaled['lon'] = train_data['lon'].to_list()\n",
    "    \n",
    "    val_data_scaled = scaler.transform(val_temp)\n",
    "    val_data_scaled = pd.DataFrame(val_data_scaled, columns = val_temp.columns)\n",
    "    val_data_scaled['cluster'] = val_data['cluster'].to_list()\n",
    "    val_data_scaled['site'] = val_data['site'].to_list()\n",
    "    val_data_scaled['lat'] = val_data['lat'].to_list()\n",
    "    val_data_scaled['lon'] = val_data['lon'].to_list()\n",
    "    \n",
    "    return train_data_scaled, val_data_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bc67b500",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method slightly modified from Shruti's code\n",
    "def impute_knn(train_data, val_data, optimal_k): \n",
    "    train_data_scaled, val_data_scaled = standardize_data(train_data, val_data)\n",
    "\n",
    "    knn = KNNImputer(n_neighbors = optimal_k)\n",
    "\n",
    "    # imputing values\n",
    "    train_data_imputed = knn.fit_transform(train_data_scaled.values)\n",
    "    train_data_imputed = pd.DataFrame(train_data_imputed, columns = train_data_scaled.columns)\n",
    "    val_data_imputed = knn.transform(val_data_scaled.values)\n",
    "    val_data_imputed = pd.DataFrame(val_data_imputed, columns = val_data_scaled.columns)\n",
    "    \n",
    "    return train_data_imputed, val_data_imputed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd097cf7",
   "metadata": {},
   "source": [
    "## Data Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7628bfd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../../Feature Matrix/processed_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3358bfa",
   "metadata": {},
   "source": [
    "## Model Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "673d8c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "COUNT_THRESH = 34\n",
    "RDM_SEED = 123\n",
    "TRAIN_TEST_PROPORTION = 0.8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89e1826a",
   "metadata": {},
   "source": [
    "## Data Transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50f101f0",
   "metadata": {},
   "source": [
    "### One-Hot Categorical Encoding and Dropping NAs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0bc3e73a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(columns = ['CBSA_NAME'], inplace=True)\n",
    "data = data_cleaning(data, dropna = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcab4752",
   "metadata": {},
   "source": [
    "### Data Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f6073646",
   "metadata": {},
   "outputs": [],
   "source": [
    "working_set, predict_set = data_split(data, count_thresh = COUNT_THRESH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ecd1a7e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_data = working_set\n",
    "predict_data = predict_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d567dde7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>site</th>\n",
       "      <th>priv_count</th>\n",
       "      <th>priv_pay_median</th>\n",
       "      <th>mcare_los</th>\n",
       "      <th>mcare_pay_median</th>\n",
       "      <th>lon</th>\n",
       "      <th>lat</th>\n",
       "      <th>Hospitals</th>\n",
       "      <th>PctTeaching</th>\n",
       "      <th>...</th>\n",
       "      <th>group_revision_tha</th>\n",
       "      <th>group_revision_tka</th>\n",
       "      <th>group_robotic_assisted_surgery</th>\n",
       "      <th>group_rtc_slap_bank</th>\n",
       "      <th>group_septoplasty</th>\n",
       "      <th>group_tha</th>\n",
       "      <th>group_thoracic</th>\n",
       "      <th>group_tka</th>\n",
       "      <th>group_tpa</th>\n",
       "      <th>group_tsa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>63</td>\n",
       "      <td>24289.900</td>\n",
       "      <td>2.549296</td>\n",
       "      <td>8794.190</td>\n",
       "      <td>-96.920913</td>\n",
       "      <td>32.707875</td>\n",
       "      <td>114.0</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>51</td>\n",
       "      <td>21408.000</td>\n",
       "      <td>3.543210</td>\n",
       "      <td>10395.160</td>\n",
       "      <td>-95.622552</td>\n",
       "      <td>29.598443</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.088398</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>29757.100</td>\n",
       "      <td>3.918699</td>\n",
       "      <td>14174.100</td>\n",
       "      <td>-74.005954</td>\n",
       "      <td>40.712776</td>\n",
       "      <td>143.0</td>\n",
       "      <td>0.552448</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>66</td>\n",
       "      <td>25240.905</td>\n",
       "      <td>3.241935</td>\n",
       "      <td>10144.445</td>\n",
       "      <td>-96.920913</td>\n",
       "      <td>32.707875</td>\n",
       "      <td>114.0</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>34963.900</td>\n",
       "      <td>3.262295</td>\n",
       "      <td>14008.190</td>\n",
       "      <td>-74.005954</td>\n",
       "      <td>40.712776</td>\n",
       "      <td>143.0</td>\n",
       "      <td>0.552448</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46235</th>\n",
       "      <td>2020</td>\n",
       "      <td>0</td>\n",
       "      <td>156</td>\n",
       "      <td>5909.230</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-80.101620</td>\n",
       "      <td>26.469680</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.238095</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46237</th>\n",
       "      <td>2020</td>\n",
       "      <td>0</td>\n",
       "      <td>128</td>\n",
       "      <td>4582.570</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-97.330050</td>\n",
       "      <td>37.687180</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.190476</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46238</th>\n",
       "      <td>2020</td>\n",
       "      <td>0</td>\n",
       "      <td>267</td>\n",
       "      <td>5316.990</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-75.165240</td>\n",
       "      <td>39.952630</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46241</th>\n",
       "      <td>2020</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>5378.645</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-80.244220</td>\n",
       "      <td>36.099860</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46243</th>\n",
       "      <td>2020</td>\n",
       "      <td>0</td>\n",
       "      <td>68</td>\n",
       "      <td>3665.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-80.543850</td>\n",
       "      <td>41.291970</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5364 rows × 82 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       year  site  priv_count  priv_pay_median  mcare_los  mcare_pay_median  \\\n",
       "40     2018     1          63        24289.900   2.549296          8794.190   \n",
       "70     2018     1          51        21408.000   3.543210         10395.160   \n",
       "112    2018     1          64        29757.100   3.918699         14174.100   \n",
       "219    2019     1          66        25240.905   3.241935         10144.445   \n",
       "275    2019     1          45        34963.900   3.262295         14008.190   \n",
       "...     ...   ...         ...              ...        ...               ...   \n",
       "46235  2020     0         156         5909.230        NaN               NaN   \n",
       "46237  2020     0         128         4582.570        NaN               NaN   \n",
       "46238  2020     0         267         5316.990        NaN               NaN   \n",
       "46241  2020     0          36         5378.645        NaN               NaN   \n",
       "46243  2020     0          68         3665.000        NaN               NaN   \n",
       "\n",
       "             lon        lat  Hospitals  PctTeaching  ...  group_revision_tha  \\\n",
       "40    -96.920913  32.707875      114.0     0.105263  ...                   0   \n",
       "70    -95.622552  29.598443      181.0     0.088398  ...                   0   \n",
       "112   -74.005954  40.712776      143.0     0.552448  ...                   0   \n",
       "219   -96.920913  32.707875      114.0     0.105263  ...                   0   \n",
       "275   -74.005954  40.712776      143.0     0.552448  ...                   0   \n",
       "...          ...        ...        ...          ...  ...                 ...   \n",
       "46235 -80.101620  26.469680       21.0     0.238095  ...                   0   \n",
       "46237 -97.330050  37.687180       21.0     0.190476  ...                   0   \n",
       "46238 -75.165240  39.952630        8.0     0.375000  ...                   0   \n",
       "46241 -80.244220  36.099860       11.0     0.363636  ...                   0   \n",
       "46243 -80.543850  41.291970       16.0     0.500000  ...                   0   \n",
       "\n",
       "       group_revision_tka  group_robotic_assisted_surgery  \\\n",
       "40                      0                               0   \n",
       "70                      0                               0   \n",
       "112                     0                               0   \n",
       "219                     0                               0   \n",
       "275                     0                               0   \n",
       "...                   ...                             ...   \n",
       "46235                   0                               0   \n",
       "46237                   0                               0   \n",
       "46238                   0                               0   \n",
       "46241                   0                               0   \n",
       "46243                   0                               0   \n",
       "\n",
       "       group_rtc_slap_bank  group_septoplasty  group_tha  group_thoracic  \\\n",
       "40                       0                  0          0               0   \n",
       "70                       0                  0          0               0   \n",
       "112                      0                  0          0               0   \n",
       "219                      0                  0          0               0   \n",
       "275                      0                  0          0               0   \n",
       "...                    ...                ...        ...             ...   \n",
       "46235                    1                  0          0               0   \n",
       "46237                    1                  0          0               0   \n",
       "46238                    1                  0          0               0   \n",
       "46241                    1                  0          0               0   \n",
       "46243                    1                  0          0               0   \n",
       "\n",
       "       group_tka  group_tpa  group_tsa  \n",
       "40             0          0          0  \n",
       "70             0          0          0  \n",
       "112            0          0          0  \n",
       "219            0          0          0  \n",
       "275            0          0          0  \n",
       "...          ...        ...        ...  \n",
       "46235          0          0          0  \n",
       "46237          0          0          0  \n",
       "46238          0          0          0  \n",
       "46241          0          0          0  \n",
       "46243          0          0          0  \n",
       "\n",
       "[5364 rows x 82 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(model_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21de2580",
   "metadata": {},
   "source": [
    "## Dev/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "42e7371f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>site</th>\n",
       "      <th>priv_count</th>\n",
       "      <th>mcare_los</th>\n",
       "      <th>mcare_pay_median</th>\n",
       "      <th>lon</th>\n",
       "      <th>lat</th>\n",
       "      <th>Hospitals</th>\n",
       "      <th>PctTeaching</th>\n",
       "      <th>PctLargeHospital</th>\n",
       "      <th>...</th>\n",
       "      <th>group_revision_tha</th>\n",
       "      <th>group_revision_tka</th>\n",
       "      <th>group_robotic_assisted_surgery</th>\n",
       "      <th>group_rtc_slap_bank</th>\n",
       "      <th>group_septoplasty</th>\n",
       "      <th>group_tha</th>\n",
       "      <th>group_thoracic</th>\n",
       "      <th>group_tka</th>\n",
       "      <th>group_tpa</th>\n",
       "      <th>group_tsa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>63</td>\n",
       "      <td>2.549296</td>\n",
       "      <td>8794.190</td>\n",
       "      <td>-96.920913</td>\n",
       "      <td>32.707875</td>\n",
       "      <td>114.0</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>51</td>\n",
       "      <td>3.543210</td>\n",
       "      <td>10395.160</td>\n",
       "      <td>-95.622552</td>\n",
       "      <td>29.598443</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.088398</td>\n",
       "      <td>0.060773</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>3.918699</td>\n",
       "      <td>14174.100</td>\n",
       "      <td>-74.005954</td>\n",
       "      <td>40.712776</td>\n",
       "      <td>143.0</td>\n",
       "      <td>0.552448</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>66</td>\n",
       "      <td>3.241935</td>\n",
       "      <td>10144.445</td>\n",
       "      <td>-96.920913</td>\n",
       "      <td>32.707875</td>\n",
       "      <td>114.0</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>3.262295</td>\n",
       "      <td>14008.190</td>\n",
       "      <td>-74.005954</td>\n",
       "      <td>40.712776</td>\n",
       "      <td>143.0</td>\n",
       "      <td>0.552448</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46235</th>\n",
       "      <td>2020</td>\n",
       "      <td>0</td>\n",
       "      <td>156</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-80.101620</td>\n",
       "      <td>26.469680</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.238095</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46237</th>\n",
       "      <td>2020</td>\n",
       "      <td>0</td>\n",
       "      <td>128</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-97.330050</td>\n",
       "      <td>37.687180</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.190476</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46238</th>\n",
       "      <td>2020</td>\n",
       "      <td>0</td>\n",
       "      <td>267</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-75.165240</td>\n",
       "      <td>39.952630</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46241</th>\n",
       "      <td>2020</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-80.244220</td>\n",
       "      <td>36.099860</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46243</th>\n",
       "      <td>2020</td>\n",
       "      <td>0</td>\n",
       "      <td>68</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-80.543850</td>\n",
       "      <td>41.291970</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5364 rows × 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       year  site  priv_count  mcare_los  mcare_pay_median        lon  \\\n",
       "40     2018     1          63   2.549296          8794.190 -96.920913   \n",
       "70     2018     1          51   3.543210         10395.160 -95.622552   \n",
       "112    2018     1          64   3.918699         14174.100 -74.005954   \n",
       "219    2019     1          66   3.241935         10144.445 -96.920913   \n",
       "275    2019     1          45   3.262295         14008.190 -74.005954   \n",
       "...     ...   ...         ...        ...               ...        ...   \n",
       "46235  2020     0         156        NaN               NaN -80.101620   \n",
       "46237  2020     0         128        NaN               NaN -97.330050   \n",
       "46238  2020     0         267        NaN               NaN -75.165240   \n",
       "46241  2020     0          36        NaN               NaN -80.244220   \n",
       "46243  2020     0          68        NaN               NaN -80.543850   \n",
       "\n",
       "             lat  Hospitals  PctTeaching  PctLargeHospital  ...  \\\n",
       "40     32.707875      114.0     0.105263          0.052632  ...   \n",
       "70     29.598443      181.0     0.088398          0.060773  ...   \n",
       "112    40.712776      143.0     0.552448          0.230769  ...   \n",
       "219    32.707875      114.0     0.105263          0.052632  ...   \n",
       "275    40.712776      143.0     0.552448          0.230769  ...   \n",
       "...          ...        ...          ...               ...  ...   \n",
       "46235  26.469680       21.0     0.238095          0.095238  ...   \n",
       "46237  37.687180       21.0     0.190476          0.142857  ...   \n",
       "46238  39.952630        8.0     0.375000          0.125000  ...   \n",
       "46241  36.099860       11.0     0.363636          0.181818  ...   \n",
       "46243  41.291970       16.0     0.500000          0.062500  ...   \n",
       "\n",
       "       group_revision_tha  group_revision_tka  group_robotic_assisted_surgery  \\\n",
       "40                      0                   0                               0   \n",
       "70                      0                   0                               0   \n",
       "112                     0                   0                               0   \n",
       "219                     0                   0                               0   \n",
       "275                     0                   0                               0   \n",
       "...                   ...                 ...                             ...   \n",
       "46235                   0                   0                               0   \n",
       "46237                   0                   0                               0   \n",
       "46238                   0                   0                               0   \n",
       "46241                   0                   0                               0   \n",
       "46243                   0                   0                               0   \n",
       "\n",
       "       group_rtc_slap_bank  group_septoplasty  group_tha  group_thoracic  \\\n",
       "40                       0                  0          0               0   \n",
       "70                       0                  0          0               0   \n",
       "112                      0                  0          0               0   \n",
       "219                      0                  0          0               0   \n",
       "275                      0                  0          0               0   \n",
       "...                    ...                ...        ...             ...   \n",
       "46235                    1                  0          0               0   \n",
       "46237                    1                  0          0               0   \n",
       "46238                    1                  0          0               0   \n",
       "46241                    1                  0          0               0   \n",
       "46243                    1                  0          0               0   \n",
       "\n",
       "       group_tka  group_tpa  group_tsa  \n",
       "40             0          0          0  \n",
       "70             0          0          0  \n",
       "112            0          0          0  \n",
       "219            0          0          0  \n",
       "275            0          0          0  \n",
       "...          ...        ...        ...  \n",
       "46235          0          0          0  \n",
       "46237          0          0          0  \n",
       "46238          0          0          0  \n",
       "46241          0          0          0  \n",
       "46243          0          0          0  \n",
       "\n",
       "[5364 rows x 81 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "40       24289.900\n",
       "70       21408.000\n",
       "112      29757.100\n",
       "219      25240.905\n",
       "275      34963.900\n",
       "           ...    \n",
       "46235     5909.230\n",
       "46237     4582.570\n",
       "46238     5316.990\n",
       "46241     5378.645\n",
       "46243     3665.000\n",
       "Name: priv_pay_median, Length: 5364, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_input = model_data.drop(columns=[\"priv_pay_median\"])\n",
    "y_input = model_data[\"priv_pay_median\"]\n",
    "\n",
    "display(X_input)\n",
    "display(y_input)\n",
    "\n",
    "X_dev, X_test, y_dev, y_test = train_test_split(X_input,\n",
    "                                                y_input,\n",
    "                                                train_size = TRAIN_TEST_PROPORTION,\n",
    "                                                random_state = RDM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab0071b4",
   "metadata": {},
   "source": [
    "## Split Model Data by Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "112b4645",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.107692307692307\n",
      "3.8518518518518516\n",
      "3.6666666666666665\n"
     ]
    }
   ],
   "source": [
    "X_dev_list = []\n",
    "y_dev_list = []\n",
    "X_test_list = []\n",
    "y_test_list = []\n",
    "\n",
    "for cluster_label in model_data[\"cluster\"].unique():\n",
    "    X_dev_list.append(X_dev[X_dev[\"cluster\"] == cluster_label])\n",
    "    y_dev_list.append(y_dev[X_dev[\"cluster\"] == cluster_label])\n",
    "    X_test_list.append(X_test[X_test[\"cluster\"] == cluster_label])\n",
    "    y_test_list.append(y_test[X_test[\"cluster\"] == cluster_label])\n",
    "    \n",
    "    print(X_dev_list[-1].shape[0] / X_test_list[-1].shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "207d1fcf",
   "metadata": {},
   "source": [
    "## Run XGBoost model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c0a0878e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rogmo\\anaconda3\\lib\\site-packages\\xgboost\\data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "\nAll the 270 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n39 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\rogmo\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\rogmo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 506, in inner_f\n    return f(**kwargs)\n  File \"C:\\Users\\rogmo\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 1533, in fit\n    super().fit(**args)\n  File \"C:\\Users\\rogmo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 506, in inner_f\n    return f(**kwargs)\n  File \"C:\\Users\\rogmo\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 761, in fit\n    train_dmatrix, evals = _wrap_evaluation_matrices(\n  File \"C:\\Users\\rogmo\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 286, in _wrap_evaluation_matrices\n    train_dmatrix = create_dmatrix(\n  File \"C:\\Users\\rogmo\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 775, in <lambda>\n    create_dmatrix=lambda **kwargs: DMatrix(nthread=self.n_jobs, **kwargs),\n  File \"C:\\Users\\rogmo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 506, in inner_f\n    return f(**kwargs)\n  File \"C:\\Users\\rogmo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 616, in __init__\n    handle, feature_names, feature_types = dispatch_data_backend(\n  File \"C:\\Users\\rogmo\\anaconda3\\lib\\site-packages\\xgboost\\data.py\", line 707, in dispatch_data_backend\n    return _from_pandas_df(data, enable_categorical, missing, threads,\n  File \"C:\\Users\\rogmo\\anaconda3\\lib\\site-packages\\xgboost\\data.py\", line 299, in _from_pandas_df\n    return _from_numpy_array(data, missing, nthread, feature_names,\n  File \"C:\\Users\\rogmo\\anaconda3\\lib\\site-packages\\xgboost\\data.py\", line 178, in _from_numpy_array\n    _check_call(\n  File \"C:\\Users\\rogmo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 218, in _check_call\n    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\nxgboost.core.XGBoostError: [22:56:07] C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\data\\data.cc:981: Check failed: valid: Input data contains `inf` or `nan`\n\n--------------------------------------------------------------------------------\n96 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\rogmo\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\rogmo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 506, in inner_f\n    return f(**kwargs)\n  File \"C:\\Users\\rogmo\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 1533, in fit\n    super().fit(**args)\n  File \"C:\\Users\\rogmo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 506, in inner_f\n    return f(**kwargs)\n  File \"C:\\Users\\rogmo\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 761, in fit\n    train_dmatrix, evals = _wrap_evaluation_matrices(\n  File \"C:\\Users\\rogmo\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 286, in _wrap_evaluation_matrices\n    train_dmatrix = create_dmatrix(\n  File \"C:\\Users\\rogmo\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 775, in <lambda>\n    create_dmatrix=lambda **kwargs: DMatrix(nthread=self.n_jobs, **kwargs),\n  File \"C:\\Users\\rogmo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 506, in inner_f\n    return f(**kwargs)\n  File \"C:\\Users\\rogmo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 616, in __init__\n    handle, feature_names, feature_types = dispatch_data_backend(\n  File \"C:\\Users\\rogmo\\anaconda3\\lib\\site-packages\\xgboost\\data.py\", line 707, in dispatch_data_backend\n    return _from_pandas_df(data, enable_categorical, missing, threads,\n  File \"C:\\Users\\rogmo\\anaconda3\\lib\\site-packages\\xgboost\\data.py\", line 299, in _from_pandas_df\n    return _from_numpy_array(data, missing, nthread, feature_names,\n  File \"C:\\Users\\rogmo\\anaconda3\\lib\\site-packages\\xgboost\\data.py\", line 178, in _from_numpy_array\n    _check_call(\n  File \"C:\\Users\\rogmo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 218, in _check_call\n    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\nxgboost.core.XGBoostError: [22:56:08] C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\data\\data.cc:981: Check failed: valid: Input data contains `inf` or `nan`\n\n--------------------------------------------------------------------------------\n95 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\rogmo\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\rogmo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 506, in inner_f\n    return f(**kwargs)\n  File \"C:\\Users\\rogmo\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 1533, in fit\n    super().fit(**args)\n  File \"C:\\Users\\rogmo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 506, in inner_f\n    return f(**kwargs)\n  File \"C:\\Users\\rogmo\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 761, in fit\n    train_dmatrix, evals = _wrap_evaluation_matrices(\n  File \"C:\\Users\\rogmo\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 286, in _wrap_evaluation_matrices\n    train_dmatrix = create_dmatrix(\n  File \"C:\\Users\\rogmo\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 775, in <lambda>\n    create_dmatrix=lambda **kwargs: DMatrix(nthread=self.n_jobs, **kwargs),\n  File \"C:\\Users\\rogmo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 506, in inner_f\n    return f(**kwargs)\n  File \"C:\\Users\\rogmo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 616, in __init__\n    handle, feature_names, feature_types = dispatch_data_backend(\n  File \"C:\\Users\\rogmo\\anaconda3\\lib\\site-packages\\xgboost\\data.py\", line 707, in dispatch_data_backend\n    return _from_pandas_df(data, enable_categorical, missing, threads,\n  File \"C:\\Users\\rogmo\\anaconda3\\lib\\site-packages\\xgboost\\data.py\", line 299, in _from_pandas_df\n    return _from_numpy_array(data, missing, nthread, feature_names,\n  File \"C:\\Users\\rogmo\\anaconda3\\lib\\site-packages\\xgboost\\data.py\", line 178, in _from_numpy_array\n    _check_call(\n  File \"C:\\Users\\rogmo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 218, in _check_call\n    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\nxgboost.core.XGBoostError: [22:56:09] C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\data\\data.cc:981: Check failed: valid: Input data contains `inf` or `nan`\n\n--------------------------------------------------------------------------------\n40 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\rogmo\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\rogmo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 506, in inner_f\n    return f(**kwargs)\n  File \"C:\\Users\\rogmo\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 1533, in fit\n    super().fit(**args)\n  File \"C:\\Users\\rogmo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 506, in inner_f\n    return f(**kwargs)\n  File \"C:\\Users\\rogmo\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 761, in fit\n    train_dmatrix, evals = _wrap_evaluation_matrices(\n  File \"C:\\Users\\rogmo\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 286, in _wrap_evaluation_matrices\n    train_dmatrix = create_dmatrix(\n  File \"C:\\Users\\rogmo\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 775, in <lambda>\n    create_dmatrix=lambda **kwargs: DMatrix(nthread=self.n_jobs, **kwargs),\n  File \"C:\\Users\\rogmo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 506, in inner_f\n    return f(**kwargs)\n  File \"C:\\Users\\rogmo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 616, in __init__\n    handle, feature_names, feature_types = dispatch_data_backend(\n  File \"C:\\Users\\rogmo\\anaconda3\\lib\\site-packages\\xgboost\\data.py\", line 707, in dispatch_data_backend\n    return _from_pandas_df(data, enable_categorical, missing, threads,\n  File \"C:\\Users\\rogmo\\anaconda3\\lib\\site-packages\\xgboost\\data.py\", line 299, in _from_pandas_df\n    return _from_numpy_array(data, missing, nthread, feature_names,\n  File \"C:\\Users\\rogmo\\anaconda3\\lib\\site-packages\\xgboost\\data.py\", line 178, in _from_numpy_array\n    _check_call(\n  File \"C:\\Users\\rogmo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 218, in _check_call\n    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\nxgboost.core.XGBoostError: [22:56:10] C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\data\\data.cc:981: Check failed: valid: Input data contains `inf` or `nan`\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [14]\u001b[0m, in \u001b[0;36m<cell line: 7>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     44\u001b[0m     xgb_param_tuning_model \u001b[38;5;241m=\u001b[39m xgb\u001b[38;5;241m.\u001b[39mXGBRFRegressor(monotone_constraints \u001b[38;5;241m=\u001b[39m mono\u001b[38;5;66;03m#,\u001b[39;00m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;66;03m#                                                 n_estimators = 250,\u001b[39;00m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;66;03m#                                                 max_depth=25\u001b[39;00m\n\u001b[0;32m     47\u001b[0m                                                )\n\u001b[0;32m     49\u001b[0m     xgb_mono_model \u001b[38;5;241m=\u001b[39m GridSearchCV(xgb_param_tuning_model, param_grid, scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mneg_mean_absolute_percentage_error\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 50\u001b[0m     \u001b[43mxgb_mono_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     52\u001b[0m     \u001b[38;5;66;03m# Output optimal params (if applicable)\u001b[39;00m\n\u001b[0;32m     53\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest parameters (if grid search was applied): \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mxgb_mono_model\u001b[38;5;241m.\u001b[39mbest_params_\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:875\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    869\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m    870\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    871\u001b[0m     )\n\u001b[0;32m    873\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m--> 875\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    877\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    878\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    879\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1379\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1377\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1378\u001b[0m     \u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1379\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:852\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    845\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m!=\u001b[39m n_candidates \u001b[38;5;241m*\u001b[39m n_splits:\n\u001b[0;32m    846\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    847\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcv.split and cv.get_n_splits returned \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    848\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minconsistent results. Expected \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    849\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msplits, got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(n_splits, \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m n_candidates)\n\u001b[0;32m    850\u001b[0m     )\n\u001b[1;32m--> 852\u001b[0m \u001b[43m_warn_or_raise_about_fit_failures\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    854\u001b[0m \u001b[38;5;66;03m# For callable self.scoring, the return type is only know after\u001b[39;00m\n\u001b[0;32m    855\u001b[0m \u001b[38;5;66;03m# calling. If the return type is a dictionary, the error scores\u001b[39;00m\n\u001b[0;32m    856\u001b[0m \u001b[38;5;66;03m# can now be inserted with the correct key. The type checking\u001b[39;00m\n\u001b[0;32m    857\u001b[0m \u001b[38;5;66;03m# of out will be done in `_insert_error_scores`.\u001b[39;00m\n\u001b[0;32m    858\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m callable(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscoring):\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:367\u001b[0m, in \u001b[0;36m_warn_or_raise_about_fit_failures\u001b[1;34m(results, error_score)\u001b[0m\n\u001b[0;32m    360\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num_failed_fits \u001b[38;5;241m==\u001b[39m num_fits:\n\u001b[0;32m    361\u001b[0m     all_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    362\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mAll the \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    363\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIt is very likely that your model is misconfigured.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    364\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou can try to debug the error by setting error_score=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    365\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    366\u001b[0m     )\n\u001b[1;32m--> 367\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(all_fits_failed_message)\n\u001b[0;32m    369\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    370\u001b[0m     some_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    371\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mnum_failed_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed out of a total of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    372\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe score on these train-test partitions for these parameters\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    376\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    377\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: \nAll the 270 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n39 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\rogmo\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\rogmo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 506, in inner_f\n    return f(**kwargs)\n  File \"C:\\Users\\rogmo\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 1533, in fit\n    super().fit(**args)\n  File \"C:\\Users\\rogmo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 506, in inner_f\n    return f(**kwargs)\n  File \"C:\\Users\\rogmo\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 761, in fit\n    train_dmatrix, evals = _wrap_evaluation_matrices(\n  File \"C:\\Users\\rogmo\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 286, in _wrap_evaluation_matrices\n    train_dmatrix = create_dmatrix(\n  File \"C:\\Users\\rogmo\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 775, in <lambda>\n    create_dmatrix=lambda **kwargs: DMatrix(nthread=self.n_jobs, **kwargs),\n  File \"C:\\Users\\rogmo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 506, in inner_f\n    return f(**kwargs)\n  File \"C:\\Users\\rogmo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 616, in __init__\n    handle, feature_names, feature_types = dispatch_data_backend(\n  File \"C:\\Users\\rogmo\\anaconda3\\lib\\site-packages\\xgboost\\data.py\", line 707, in dispatch_data_backend\n    return _from_pandas_df(data, enable_categorical, missing, threads,\n  File \"C:\\Users\\rogmo\\anaconda3\\lib\\site-packages\\xgboost\\data.py\", line 299, in _from_pandas_df\n    return _from_numpy_array(data, missing, nthread, feature_names,\n  File \"C:\\Users\\rogmo\\anaconda3\\lib\\site-packages\\xgboost\\data.py\", line 178, in _from_numpy_array\n    _check_call(\n  File \"C:\\Users\\rogmo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 218, in _check_call\n    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\nxgboost.core.XGBoostError: [22:56:07] C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\data\\data.cc:981: Check failed: valid: Input data contains `inf` or `nan`\n\n--------------------------------------------------------------------------------\n96 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\rogmo\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\rogmo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 506, in inner_f\n    return f(**kwargs)\n  File \"C:\\Users\\rogmo\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 1533, in fit\n    super().fit(**args)\n  File \"C:\\Users\\rogmo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 506, in inner_f\n    return f(**kwargs)\n  File \"C:\\Users\\rogmo\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 761, in fit\n    train_dmatrix, evals = _wrap_evaluation_matrices(\n  File \"C:\\Users\\rogmo\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 286, in _wrap_evaluation_matrices\n    train_dmatrix = create_dmatrix(\n  File \"C:\\Users\\rogmo\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 775, in <lambda>\n    create_dmatrix=lambda **kwargs: DMatrix(nthread=self.n_jobs, **kwargs),\n  File \"C:\\Users\\rogmo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 506, in inner_f\n    return f(**kwargs)\n  File \"C:\\Users\\rogmo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 616, in __init__\n    handle, feature_names, feature_types = dispatch_data_backend(\n  File \"C:\\Users\\rogmo\\anaconda3\\lib\\site-packages\\xgboost\\data.py\", line 707, in dispatch_data_backend\n    return _from_pandas_df(data, enable_categorical, missing, threads,\n  File \"C:\\Users\\rogmo\\anaconda3\\lib\\site-packages\\xgboost\\data.py\", line 299, in _from_pandas_df\n    return _from_numpy_array(data, missing, nthread, feature_names,\n  File \"C:\\Users\\rogmo\\anaconda3\\lib\\site-packages\\xgboost\\data.py\", line 178, in _from_numpy_array\n    _check_call(\n  File \"C:\\Users\\rogmo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 218, in _check_call\n    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\nxgboost.core.XGBoostError: [22:56:08] C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\data\\data.cc:981: Check failed: valid: Input data contains `inf` or `nan`\n\n--------------------------------------------------------------------------------\n95 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\rogmo\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\rogmo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 506, in inner_f\n    return f(**kwargs)\n  File \"C:\\Users\\rogmo\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 1533, in fit\n    super().fit(**args)\n  File \"C:\\Users\\rogmo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 506, in inner_f\n    return f(**kwargs)\n  File \"C:\\Users\\rogmo\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 761, in fit\n    train_dmatrix, evals = _wrap_evaluation_matrices(\n  File \"C:\\Users\\rogmo\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 286, in _wrap_evaluation_matrices\n    train_dmatrix = create_dmatrix(\n  File \"C:\\Users\\rogmo\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 775, in <lambda>\n    create_dmatrix=lambda **kwargs: DMatrix(nthread=self.n_jobs, **kwargs),\n  File \"C:\\Users\\rogmo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 506, in inner_f\n    return f(**kwargs)\n  File \"C:\\Users\\rogmo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 616, in __init__\n    handle, feature_names, feature_types = dispatch_data_backend(\n  File \"C:\\Users\\rogmo\\anaconda3\\lib\\site-packages\\xgboost\\data.py\", line 707, in dispatch_data_backend\n    return _from_pandas_df(data, enable_categorical, missing, threads,\n  File \"C:\\Users\\rogmo\\anaconda3\\lib\\site-packages\\xgboost\\data.py\", line 299, in _from_pandas_df\n    return _from_numpy_array(data, missing, nthread, feature_names,\n  File \"C:\\Users\\rogmo\\anaconda3\\lib\\site-packages\\xgboost\\data.py\", line 178, in _from_numpy_array\n    _check_call(\n  File \"C:\\Users\\rogmo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 218, in _check_call\n    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\nxgboost.core.XGBoostError: [22:56:09] C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\data\\data.cc:981: Check failed: valid: Input data contains `inf` or `nan`\n\n--------------------------------------------------------------------------------\n40 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\rogmo\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\rogmo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 506, in inner_f\n    return f(**kwargs)\n  File \"C:\\Users\\rogmo\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 1533, in fit\n    super().fit(**args)\n  File \"C:\\Users\\rogmo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 506, in inner_f\n    return f(**kwargs)\n  File \"C:\\Users\\rogmo\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 761, in fit\n    train_dmatrix, evals = _wrap_evaluation_matrices(\n  File \"C:\\Users\\rogmo\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 286, in _wrap_evaluation_matrices\n    train_dmatrix = create_dmatrix(\n  File \"C:\\Users\\rogmo\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 775, in <lambda>\n    create_dmatrix=lambda **kwargs: DMatrix(nthread=self.n_jobs, **kwargs),\n  File \"C:\\Users\\rogmo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 506, in inner_f\n    return f(**kwargs)\n  File \"C:\\Users\\rogmo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 616, in __init__\n    handle, feature_names, feature_types = dispatch_data_backend(\n  File \"C:\\Users\\rogmo\\anaconda3\\lib\\site-packages\\xgboost\\data.py\", line 707, in dispatch_data_backend\n    return _from_pandas_df(data, enable_categorical, missing, threads,\n  File \"C:\\Users\\rogmo\\anaconda3\\lib\\site-packages\\xgboost\\data.py\", line 299, in _from_pandas_df\n    return _from_numpy_array(data, missing, nthread, feature_names,\n  File \"C:\\Users\\rogmo\\anaconda3\\lib\\site-packages\\xgboost\\data.py\", line 178, in _from_numpy_array\n    _check_call(\n  File \"C:\\Users\\rogmo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 218, in _check_call\n    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\nxgboost.core.XGBoostError: [22:56:10] C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\data\\data.cc:981: Check failed: valid: Input data contains `inf` or `nan`\n"
     ]
    }
   ],
   "source": [
    "train_mapes = []\n",
    "train_sizes = []\n",
    "test_mapes = []\n",
    "test_sizes = []\n",
    "\n",
    "# Train test split\n",
    "for idx in range(1,len(X_dev_list)):\n",
    "\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_dev_list[idx],\n",
    "                                                        y_dev_list[idx],\n",
    "                                                        train_size = TRAIN_TEST_PROPORTION,\n",
    "                                                        random_state = RDM_SEED)\n",
    "    # KNN Here!!\n",
    "    \n",
    "    # Parameterization\n",
    "    mono = {'site': 1}\n",
    "\n",
    "    param_grid = {\n",
    "        'booster':['gbtree','dart'],\n",
    "        'colsample_bylevel':[1],\n",
    "        'colsample_bytree':[1],\n",
    "        'enable_categorical':[False],\n",
    "        'gamma':[0],\n",
    "        'gpu_id':[-1],\n",
    "        'interaction_constraints':[''],\n",
    "        'max_delta_step':[0],\n",
    "        'min_child_weight':[1],\n",
    "        'missing':[np.nan],\n",
    "        'n_estimators':[100,175,250],\n",
    "        'n_jobs':[8],\n",
    "        'predictor':['auto'],\n",
    "        'reg_alpha':[0],\n",
    "        'scale_pos_weight':[1],\n",
    "        'tree_method':['exact'],\n",
    "        'validate_parameters':[1],\n",
    "        'learning_rate':[1],\n",
    "        'max_depth':[10,17,25],\n",
    "        'num_parallel_tree':[250],\n",
    "        'objective':['reg:squarederror'],\n",
    "        'subsample':[0.8],\n",
    "        'random_state':[RDM_SEED],\n",
    "        'reg_lambda':[0,0.25,0.5]\n",
    "    }\n",
    "    \n",
    "    # Create, run, and tune (if applicable) model\n",
    "    xgb_param_tuning_model = xgb.XGBRFRegressor(monotone_constraints = mono#,\n",
    "#                                                 n_estimators = 250,\n",
    "#                                                 max_depth=25\n",
    "                                               )\n",
    "    \n",
    "    xgb_mono_model = GridSearchCV(xgb_param_tuning_model, param_grid, scoring='neg_mean_absolute_percentage_error')\n",
    "    xgb_mono_model.fit(X_train, y_train)\n",
    "    \n",
    "    # Output optimal params (if applicable)\n",
    "    print(f\"Best parameters (if grid search was applied): {xgb_mono_model.best_params_}\")\n",
    "    \n",
    "    # Predict on train and test data\n",
    "    y_train_pred_xgb = xgb_mono_model.predict(X_train)\n",
    "    y_test_pred_xgb = xgb_mono_model.predict(X_test)\n",
    "\n",
    "    # Store results\n",
    "    train_sizes.append(len(X_train))\n",
    "    test_sizes.append(len(X_test))\n",
    "    train_mapes.append(mean_absolute_percentage_error(y_true=y_train, y_pred=y_train_pred_xgb))\n",
    "    test_mapes.append(mean_absolute_percentage_error(y_true=y_test, y_pred=y_test_pred_xgb))\n",
    "    \n",
    "\n",
    "train_mapes = np.array(train_mapes)\n",
    "train_sizes = np.array(train_sizes)\n",
    "test_mapes = np.array(test_mapes)\n",
    "test_sizes = np.array(test_sizes)\n",
    "\n",
    "# Output results?\n",
    "print(f\"Monotonic XGBoost with Threshold >{COUNT_THRESH} claims for training set:\")\n",
    "print(f\"Train MAPEs: {train_mapes}\")\n",
    "print(f\"Train sizes: {train_sizes}\")\n",
    "print(f\"Test MAPEs: {test_mapes}\")\n",
    "print(f\"Test sizes: {test_sizes}\")\n",
    "print(f\"Total train MAPE: {((train_mapes * train_sizes) / (train_sizes.sum())).sum()}\")\n",
    "print(f\"Total test MAPE: {((test_mapes * test_sizes) / (test_sizes.sum())).sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f136eab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
