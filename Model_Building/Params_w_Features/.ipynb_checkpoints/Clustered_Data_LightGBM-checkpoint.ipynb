{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "81eb7c6e",
   "metadata": {},
   "source": [
    "# Tree-based Models, with Clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13a4fdd5",
   "metadata": {},
   "source": [
    "## Library Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c707dca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Necessary code to import our helper functions\n",
    "import sys\n",
    "sys.path.append(\"../..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "331fb943",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Library imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from matplotlib import pyplot as plt\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from Common_Functions import add_unique_identifier, data_cleaning, hospital_data_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "820c3cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_split(data, count_col_name = 'priv_count', count_thresh = 50):\n",
    "    \"\"\"\n",
    "    This function splits the data into model set and future set. Model set is the data used to train, evaluate\n",
    "    test the model. Future data is what the model needs to predict on.\n",
    "    \n",
    "    Args:\n",
    "    data (pandas: DataFrame) - a pandas data frame with at least 3 columns - \"priv_pay_mean\", \"priv_pay_median\" and count_col_name\n",
    "    count_col_name (str) - name of the column which is thresholded to make the split\n",
    "    count_thresh (int) - threshold value used to split data on count_col_name\n",
    "    \n",
    "    Returns:\n",
    "    model_data (pandas: DataFrame) - data frame with observations that will be used to train and test model\n",
    "    future_data (pandas: DataFrame) - data frame with all observations on which model will make predictions\n",
    "    \"\"\"\n",
    "    data = data[(data['priv_pay_median'] > 0) | (data['priv_pay_median'].isnull())]\n",
    "    future_data = data[(data[count_col_name] <= count_thresh) | (data[count_col_name].isnull())]\n",
    "    model_data = data[data[count_col_name] > count_thresh]\n",
    "    model_data = model_data[model_data.priv_pay_median.notnull()]\n",
    "    return model_data, future_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd097cf7",
   "metadata": {},
   "source": [
    "## Data Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7628bfd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../../Feature Matrix/processed_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3358bfa",
   "metadata": {},
   "source": [
    "## Model Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "673d8c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "COUNT_THRESH = 34\n",
    "RDM_SEED = 123\n",
    "TRAIN_TEST_PROPORTION = 0.8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89e1826a",
   "metadata": {},
   "source": [
    "## Data Transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50f101f0",
   "metadata": {},
   "source": [
    "### One-Hot Categorical Encoding and Dropping NAs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0bc3e73a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(columns = ['CBSA_NAME', 'Unnamed: 0'], inplace=True)\n",
    "data = data_cleaning(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcab4752",
   "metadata": {},
   "source": [
    "### Data Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f6073646",
   "metadata": {},
   "outputs": [],
   "source": [
    "working_set, predict_set = data_split(data, count_thresh = COUNT_THRESH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ecd1a7e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_data = working_set\n",
    "predict_data = predict_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d567dde7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>site</th>\n",
       "      <th>priv_count</th>\n",
       "      <th>priv_pay_median</th>\n",
       "      <th>mcare_los</th>\n",
       "      <th>mcare_pay_median</th>\n",
       "      <th>lon</th>\n",
       "      <th>lat</th>\n",
       "      <th>Hospitals</th>\n",
       "      <th>PctTeaching</th>\n",
       "      <th>...</th>\n",
       "      <th>group_revision_tha</th>\n",
       "      <th>group_revision_tka</th>\n",
       "      <th>group_robotic_assisted_surgery</th>\n",
       "      <th>group_rtc_slap_bank</th>\n",
       "      <th>group_septoplasty</th>\n",
       "      <th>group_tha</th>\n",
       "      <th>group_thoracic</th>\n",
       "      <th>group_tka</th>\n",
       "      <th>group_tpa</th>\n",
       "      <th>group_tsa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>63</td>\n",
       "      <td>24289.900</td>\n",
       "      <td>2.549296</td>\n",
       "      <td>8794.190</td>\n",
       "      <td>-96.920913</td>\n",
       "      <td>32.707875</td>\n",
       "      <td>114.0</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>51</td>\n",
       "      <td>21408.000</td>\n",
       "      <td>3.543210</td>\n",
       "      <td>10395.160</td>\n",
       "      <td>-95.622552</td>\n",
       "      <td>29.598443</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.088398</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>29757.100</td>\n",
       "      <td>3.918699</td>\n",
       "      <td>14174.100</td>\n",
       "      <td>-74.005954</td>\n",
       "      <td>40.712776</td>\n",
       "      <td>143.0</td>\n",
       "      <td>0.552448</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>66</td>\n",
       "      <td>25240.905</td>\n",
       "      <td>3.241935</td>\n",
       "      <td>10144.445</td>\n",
       "      <td>-96.920913</td>\n",
       "      <td>32.707875</td>\n",
       "      <td>114.0</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>34963.900</td>\n",
       "      <td>3.262295</td>\n",
       "      <td>14008.190</td>\n",
       "      <td>-74.005954</td>\n",
       "      <td>40.712776</td>\n",
       "      <td>143.0</td>\n",
       "      <td>0.552448</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41969</th>\n",
       "      <td>2019</td>\n",
       "      <td>0</td>\n",
       "      <td>55</td>\n",
       "      <td>8614.250</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6291.420</td>\n",
       "      <td>-83.079090</td>\n",
       "      <td>42.810540</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.433333</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41993</th>\n",
       "      <td>2020</td>\n",
       "      <td>0</td>\n",
       "      <td>62</td>\n",
       "      <td>11590.770</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6628.030</td>\n",
       "      <td>-84.294090</td>\n",
       "      <td>34.075380</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.162500</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42065</th>\n",
       "      <td>2020</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>20492.920</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7015.710</td>\n",
       "      <td>-95.622550</td>\n",
       "      <td>29.598440</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.088398</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42110</th>\n",
       "      <td>2020</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>13777.100</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8517.130</td>\n",
       "      <td>-74.005950</td>\n",
       "      <td>40.712780</td>\n",
       "      <td>143.0</td>\n",
       "      <td>0.552448</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42189</th>\n",
       "      <td>2020</td>\n",
       "      <td>0</td>\n",
       "      <td>48</td>\n",
       "      <td>8874.140</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7132.820</td>\n",
       "      <td>-83.079090</td>\n",
       "      <td>42.810540</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.433333</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3509 rows Ã— 82 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       year  site  priv_count  priv_pay_median  mcare_los  mcare_pay_median  \\\n",
       "40     2018     1          63        24289.900   2.549296          8794.190   \n",
       "70     2018     1          51        21408.000   3.543210         10395.160   \n",
       "112    2018     1          64        29757.100   3.918699         14174.100   \n",
       "219    2019     1          66        25240.905   3.241935         10144.445   \n",
       "275    2019     1          45        34963.900   3.262295         14008.190   \n",
       "...     ...   ...         ...              ...        ...               ...   \n",
       "41969  2019     0          55         8614.250   0.000000          6291.420   \n",
       "41993  2020     0          62        11590.770   0.000000          6628.030   \n",
       "42065  2020     0          39        20492.920   0.000000          7015.710   \n",
       "42110  2020     0          44        13777.100   0.000000          8517.130   \n",
       "42189  2020     0          48         8874.140   0.000000          7132.820   \n",
       "\n",
       "             lon        lat  Hospitals  PctTeaching  ...  group_revision_tha  \\\n",
       "40    -96.920913  32.707875      114.0     0.105263  ...                   0   \n",
       "70    -95.622552  29.598443      181.0     0.088398  ...                   0   \n",
       "112   -74.005954  40.712776      143.0     0.552448  ...                   0   \n",
       "219   -96.920913  32.707875      114.0     0.105263  ...                   0   \n",
       "275   -74.005954  40.712776      143.0     0.552448  ...                   0   \n",
       "...          ...        ...        ...          ...  ...                 ...   \n",
       "41969 -83.079090  42.810540       30.0     0.433333  ...                   0   \n",
       "41993 -84.294090  34.075380       80.0     0.162500  ...                   0   \n",
       "42065 -95.622550  29.598440      181.0     0.088398  ...                   0   \n",
       "42110 -74.005950  40.712780      143.0     0.552448  ...                   0   \n",
       "42189 -83.079090  42.810540       30.0     0.433333  ...                   0   \n",
       "\n",
       "       group_revision_tka  group_robotic_assisted_surgery  \\\n",
       "40                      0                               0   \n",
       "70                      0                               0   \n",
       "112                     0                               0   \n",
       "219                     0                               0   \n",
       "275                     0                               0   \n",
       "...                   ...                             ...   \n",
       "41969                   0                               0   \n",
       "41993                   0                               0   \n",
       "42065                   0                               0   \n",
       "42110                   0                               0   \n",
       "42189                   0                               0   \n",
       "\n",
       "       group_rtc_slap_bank  group_septoplasty  group_tha  group_thoracic  \\\n",
       "40                       0                  0          0               0   \n",
       "70                       0                  0          0               0   \n",
       "112                      0                  0          0               0   \n",
       "219                      0                  0          0               0   \n",
       "275                      0                  0          0               0   \n",
       "...                    ...                ...        ...             ...   \n",
       "41969                    0                  0          0               0   \n",
       "41993                    0                  0          0               0   \n",
       "42065                    0                  0          0               0   \n",
       "42110                    0                  0          0               0   \n",
       "42189                    0                  0          0               0   \n",
       "\n",
       "       group_tka  group_tpa  group_tsa  \n",
       "40             0          0          0  \n",
       "70             0          0          0  \n",
       "112            0          0          0  \n",
       "219            0          0          0  \n",
       "275            0          0          0  \n",
       "...          ...        ...        ...  \n",
       "41969          0          0          0  \n",
       "41993          0          0          0  \n",
       "42065          0          0          0  \n",
       "42110          0          0          0  \n",
       "42189          0          0          0  \n",
       "\n",
       "[3509 rows x 82 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(model_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab0071b4",
   "metadata": {},
   "source": [
    "## Split Model Data by Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "112b4645",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_data_list = []\n",
    "for cluster_label in model_data[\"cluster\"].unique():\n",
    "    cluster_data_list.append(model_data[model_data[\"cluster\"] == cluster_label])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "207d1fcf",
   "metadata": {},
   "source": [
    "## Run LightGBM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c0a0878e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters (if grid search was applied): {}\n",
      "Best parameters (if grid search was applied): {}\n",
      "Best parameters (if grid search was applied): {}\n",
      "Monotonic LightGBM with Threshold >34 claims for training set:\n",
      "Train MAPEs: [0.03096931 0.02497394 0.0322169 ]\n",
      "Train sizes: [1577 1082  147]\n",
      "Test MAPEs: [0.14498769 0.13623181 0.12738956]\n",
      "Test sizes: [395 271  37]\n",
      "Total train MAPE: 0.0287228416150374\n",
      "Total test MAPE: 0.14068616073085063\n"
     ]
    }
   ],
   "source": [
    "train_mapes = []\n",
    "train_sizes = []\n",
    "test_mapes = []\n",
    "test_sizes = []\n",
    "\n",
    "# Train test split\n",
    "for cluster_dataset in cluster_data_list:\n",
    "\n",
    "    X_input = cluster_dataset.drop(columns=[\"priv_pay_median\"])\n",
    "    y_input = cluster_dataset[\"priv_pay_median\"]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_input,\n",
    "                                                        y_input,\n",
    "                                                        train_size = TRAIN_TEST_PROPORTION,\n",
    "                                                        random_state = RDM_SEED)\n",
    "    # Parameterization\n",
    "    param_grid = {\n",
    "#         'boosting_type':['gbdt','dart'],\n",
    "#         'n_estimators':[150,200,250,300],\n",
    "#         'num_leaves':[60,70,80,90],\n",
    "#         'learning_rate': [0.2,0.3,0.4],\n",
    "#         'min_child_weight':[0,1],\n",
    "#         'reg_lambda':[0,0.25,0.5]\n",
    "    }\n",
    "    mono = np.array((pd.Series(X_train.columns) == \"site\").astype(int))\n",
    "    \n",
    "    # Create, run, and tune (if applicable) model\n",
    "    lgb_param_tuning_model = lgb.LGBMRegressor(boosting_type = 'dart',\n",
    "                                               monotone_constraints = mono,\n",
    "                                               learning_rate = 0.3,\n",
    "                                               n_estimators=300,\n",
    "                                               num_leaves = 80,\n",
    "                                               reg_lambda = 0.25,\n",
    "                                               min_child_weight=0\n",
    "                                             )\n",
    "    lgb_mono_model = GridSearchCV(lgb_param_tuning_model, param_grid, scoring='neg_mean_absolute_percentage_error')\n",
    "    lgb_mono_model.fit(X_train, y_train)\n",
    "    \n",
    "    # Output optimal params (if applicable)\n",
    "    print(f\"Best parameters (if grid search was applied): {lgb_mono_model.best_params_}\")\n",
    "    \n",
    "    # Predict on train and test data\n",
    "    y_train_pred_lgb = lgb_mono_model.predict(X_train)\n",
    "    y_test_pred_lgb = lgb_mono_model.predict(X_test)\n",
    "\n",
    "    # Store results\n",
    "    train_sizes.append(len(X_train))\n",
    "    test_sizes.append(len(X_test))\n",
    "    train_mapes.append(mean_absolute_percentage_error(y_true=y_train, y_pred=y_train_pred_lgb))\n",
    "    test_mapes.append(mean_absolute_percentage_error(y_true=y_test, y_pred=y_test_pred_lgb))\n",
    "    \n",
    "\n",
    "train_mapes = np.array(train_mapes)\n",
    "train_sizes = np.array(train_sizes)\n",
    "test_mapes = np.array(test_mapes)\n",
    "test_sizes = np.array(test_sizes)\n",
    "\n",
    "# Output results?\n",
    "print(f\"Monotonic LightGBM with Threshold >{COUNT_THRESH} claims for training set:\")\n",
    "print(f\"Train MAPEs: {train_mapes}\")\n",
    "print(f\"Train sizes: {train_sizes}\")\n",
    "print(f\"Test MAPEs: {test_mapes}\")\n",
    "print(f\"Test sizes: {test_sizes}\")\n",
    "print(f\"Total train MAPE: {((train_mapes * train_sizes) / (train_sizes.sum())).sum()}\")\n",
    "print(f\"Total test MAPE: {((test_mapes * test_sizes) / (test_sizes.sum())).sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f136eab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
